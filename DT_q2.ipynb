{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DT_q2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShashankKamath/DecisionTree_ML/blob/master/DT_q2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-JGW9s05T3AB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  https://github.com/random-forests/tutorials/blob/master/decision_tree.ipynb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hJQB_6vI2rRk",
        "colab_type": "code",
        "outputId": "c36a1147-a2e5-4fd9-a32d-4ee40f54ee38",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-43eecd4f-a4ec-4add-a0c7-59e187f1ae14\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-43eecd4f-a4ec-4add-a0c7-59e187f1ae14\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving hw2_question1.csv to hw2_question1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ayli7_LVL9ew",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Splitting the data into Train and Test\n"
      ]
    },
    {
      "metadata": {
        "id": "guMvinOPTvlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "648bd534-d0c0-4ed4-f52e-85f0701b1f29"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "data = pd.read_csv(\"hw2_extra.csv\")\n",
        "train_set=data.values.tolist()\n",
        "header=[\"Temperature\",\"Humidity\",\"Sky_Condition\",\"Rainy\"]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b4f275fbe059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hw2_extra.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Temperature\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Humidity\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Sky_Condition\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Rainy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: File b'hw2_extra.csv' does not exist"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uSillIK0_maA",
        "colab_type": "code",
        "outputId": "1d6960ed-ecbe-4540-901e-63016329fe70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Sky_condition</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>cloudy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>cloudy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>cloudy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>cloudy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hot</td>\n",
              "      <td>high</td>\n",
              "      <td>cloudy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Temperature Humidity Sky_condition  Output\n",
              "0         hot     high        cloudy       1\n",
              "1         hot     high        cloudy       1\n",
              "2         hot     high        cloudy       1\n",
              "3         hot     high        cloudy       1\n",
              "4         hot     high        cloudy       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "ZSFFeB1AHXrr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "data = pd.read_csv(\"hw2_question1.csv\")\n",
        "header=[\"Thickness\", \"Cellsize\", \"Cellshape\", \"Adhesion\",\"Ecellsize\",\"Nuclei\",\"Chromatin\",\"Nucleoli\",\"Mitosis\",\"Class\"]\n",
        "data.columns=header\n",
        "data=shuffle(data)\n",
        "data=data.reset_index(drop=True)\n",
        "#   data = data.sample(frac=1).reset_index(drop=True)\n",
        "train_data=pd.DataFrame()\n",
        "test_data=pd.DataFrame()\n",
        "class_2_count=[295,148]\n",
        "class_4_count=[159,80]\n",
        "for i in range(0,data.shape[0]):\n",
        "    if(data.loc[i,'Class']==2 and class_2_count[0]<=295 and class_2_count[0]>0):\n",
        "        train_data=train_data.append(data.iloc[i])\n",
        "        class_2_count[0]-=1\n",
        "    if(data.loc[i,'Class']==4 and class_4_count[0]<=159 and class_4_count[0]>0):\n",
        "        train_data=train_data.append(data.iloc[i])\n",
        "        class_4_count[0]-=1\n",
        "    if(data.loc[i,'Class']==2 and class_2_count[1]<=148 and class_2_count[1]>0):\n",
        "        test_data=test_data.append(data.iloc[i])\n",
        "        class_2_count[1]-=1\n",
        "    if(data.loc[i,'Class']==4 and class_4_count[1]<=80 and class_4_count[1]>0):\n",
        "        test_data=test_data.append(data.iloc[i])\n",
        "        class_4_count[1]-=1\n",
        "train_data=train_data[header]\n",
        "test_data=test_data[header]\n",
        "data_set=data.values.tolist()\n",
        "train_set=train_data.values.tolist()\n",
        "test_set=test_data.values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KlEVPw3t_qbo",
        "colab_type": "code",
        "outputId": "2debb339-8784-428b-f322-d2b12292868b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "def unique_vals(rows, col):\n",
        "    \"\"\"Find the unique values for a column in a dataset.\"\"\"\n",
        "    return set([row[col] for row in rows])\n",
        "unique_vals(train_set, 0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "kgAaOd0xAEJt",
        "colab_type": "code",
        "outputId": "3eeed4ff-7d23-4437-8685-f941584cd8b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "def class_counts(rows):\n",
        "    \"\"\"Counts the number of each type of example in a dataset.\"\"\"\n",
        "    counts = {}  # a dictionary of label -> count.\n",
        "    for row in rows:\n",
        "        # in our dataset format, the label is always the last column\n",
        "        label = row[-1]\n",
        "        if label not in counts:\n",
        "            counts[label] = 0\n",
        "        counts[label] += 1\n",
        "    return counts\n",
        "  \n",
        "class_counts(train_set)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{2.0: 295, 4.0: 159}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "iiNMEXJdB-9j",
        "colab_type": "code",
        "outputId": "61de81e4-5bfa-49e9-882c-986813fd0598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "def is_numeric(value):\n",
        "    \"\"\"Test if a value is numeric.\"\"\"\n",
        "    return isinstance(value, int) or isinstance(value, float)\n",
        "is_numeric(7)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "I1Jo7aMYCMut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Question:\n",
        "    \"\"\"A Question is used to partition a dataset.\n",
        "\n",
        "    This class just records a 'column number' (e.g., 0 for Color) and a\n",
        "    'column value' (e.g., Green). The 'match' method is used to compare\n",
        "    the feature value in an example to the feature value stored in the\n",
        "    question. See the demo below.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, column, value):\n",
        "        self.column = column\n",
        "        self.value = value\n",
        "\n",
        "    def match(self, example):\n",
        "        # Compare the feature value in an example to the\n",
        "        # feature value in this question.\n",
        "        val = example[self.column]\n",
        "        if is_numeric(val):\n",
        "            return val >= self.value\n",
        "        else:\n",
        "            return val == self.value\n",
        "\n",
        "    def __repr__(self):\n",
        "        # This is just a helper method to print\n",
        "        # the question in a readable format.\n",
        "        condition = \"==\"\n",
        "        if is_numeric(self.value):\n",
        "            condition = \">=\"\n",
        "        return \"Is %s %s %s?\" % (header[self.column], condition, str(self.value))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ERphJAFXCmxE",
        "colab_type": "code",
        "outputId": "8fd7369e-b8f1-4c46-ef59-7b5ddcd1cde5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "q = Question(6,7)\n",
        "example = train_set[0]\n",
        "q.match(example)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "ervjNTmtENF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partition(rows, question):\n",
        "    \"\"\"Partitions a dataset.\n",
        "\n",
        "    For each row in the dataset, check if it matches the question. If\n",
        "    so, add it to 'true rows', otherwise, add it to 'false rows'.\n",
        "    \"\"\"\n",
        "    true_rows, false_rows = [], []\n",
        "    for row in rows:\n",
        "        if question.match(row):\n",
        "            true_rows.append(row)\n",
        "        else:\n",
        "            false_rows.append(row)\n",
        "    return true_rows, false_rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F1chNkv9ESqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# true_rows, false_rows = partition(train_set, Question(0, 2))\n",
        "# true_rows"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UkITmm5xFZsG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This will give all values less than two in the first column"
      ]
    },
    {
      "metadata": {
        "id": "FnL9J7ZKFYnv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gini(rows):\n",
        "    \"\"\"Calculate the Gini Impurity for a list of rows.\n",
        "\n",
        "    There are a few different ways to do this, I thought this one was\n",
        "    the most concise. See:\n",
        "    https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
        "    \"\"\"\n",
        "    counts = class_counts(rows)\n",
        "    impurity = 1\n",
        "    for lbl in counts:\n",
        "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
        "        impurity -= prob_of_lbl**2\n",
        "    return impurity "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNIbuyYtFmeb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def info_gain(left, right, current_uncertainty):\n",
        "    \"\"\"Information Gain.\n",
        "\n",
        "    The uncertainty of the starting node, minus the weighted impurity of\n",
        "    two child nodes.\n",
        "    \"\"\"\n",
        "    p = float(len(left)) / (len(left) + len(right))\n",
        "    return current_uncertainty - p * gini(left) - (1 - p) * gini(right)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zPnyHTynFo49",
        "colab_type": "code",
        "outputId": "dab26e3f-1cac-4a6a-8a7a-a154bc60a7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "current_uncertainty = gini(train_set)\n",
        "current_uncertainty"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.49499999999999994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "htnar3UKF9ER",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_best_split(rows):\n",
        "    \"\"\"Find the best question to ask by iterating over every feature / value\n",
        "    and calculating the information gain.\"\"\"\n",
        "    best_gain = 0  # keep track of the best information gain\n",
        "    best_question = None  # keep train of the feature / value that produced it\n",
        "    current_uncertainty = gini(rows)\n",
        "    n_features = len(rows[0]) - 1  # number of columns\n",
        "\n",
        "    for col in range(n_features):  # for each feature\n",
        "\n",
        "        values = set([row[col] for row in rows])  # unique values in the column\n",
        "\n",
        "        for val in values:  # for each value\n",
        "\n",
        "            question = Question(col, val)\n",
        "\n",
        "            # try splitting the dataset\n",
        "            true_rows, false_rows = partition(rows, question)\n",
        "\n",
        "            # Skip this split if it doesn't divide the\n",
        "            # dataset.\n",
        "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
        "                continue\n",
        "\n",
        "            # Calculate the information gain from this split\n",
        "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
        "\n",
        "            # You actually can use '>' instead of '>=' here\n",
        "            # but I wanted the tree to look a certain way for our\n",
        "            # toy dataset.\n",
        "#             print(\"Question and gain:\",question,gain)\n",
        "            if gain >= best_gain:\n",
        "                best_gain, best_question = gain, question\n",
        "    print(\"Best Question: \",best_question)\n",
        "    print(\"Best Gain: \", best_gain)\n",
        "    return best_gain, best_question"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_NUkRm9THpkf",
        "colab_type": "code",
        "outputId": "e64e9b32-4207-483e-8792-bc853c2fb78c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "best_gain, best_question = find_best_split(train_set)\n",
        "best_question, best_gain"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question and gain: None 0\n",
            "Question and gain: Is Temperature == hot? 0.03124999999999989\n",
            "Question and gain: Is Temperature == cool? 0.031249999999999917\n",
            "Question and gain: Is Humidity == low? 0.031249999999999917\n",
            "Question and gain: Is Humidity == low? 0.031249999999999917\n",
            "Question and gain: Is Sky_Condition == clear? 0.06124999999999997\n",
            "Best Question:  Is Sky_Condition == cloudy?\n",
            "Best Gain:  0.06124999999999997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Is Sky_Condition == cloudy?, 0.06124999999999997)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "fD0XNKjnH4DZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Leaf:\n",
        "    \"\"\"A Leaf node classifies data.\n",
        "\n",
        "    This holds a dictionary of class (e.g., \"Apple\") -> number of times\n",
        "    it appears in the rows from the training data that reach this leaf.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rows):\n",
        "        self.predictions = class_counts(rows)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QqVarO3CH5w1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decision_Node:\n",
        "    \"\"\"A Decision Node asks a question.\n",
        "\n",
        "    This holds a reference to the question, and to the two child nodes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 question,\n",
        "                 true_branch,\n",
        "                 false_branch):\n",
        "        self.question = question\n",
        "        self.true_branch = true_branch\n",
        "        self.false_branch = false_branch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ucq3OZi0MTA3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_tree(node, spacing=\"\"):\n",
        "    \"\"\"World's most elegant tree printing function.\"\"\"\n",
        "\n",
        "    # Base case: we've reached a leaf\n",
        "    if isinstance(node, Leaf):\n",
        "        print (spacing + \"Predict\", node.predictions)\n",
        "        return\n",
        "\n",
        "    # Print the question at this node\n",
        "    print (spacing + str(node.question))\n",
        "\n",
        "    # Call this function recursively on the true branch\n",
        "    print (spacing + '--> True:')\n",
        "    print_tree(node.true_branch, spacing + \"  \")\n",
        "\n",
        "    # Call this function recursively on the false branch\n",
        "    print (spacing + '--> False:')\n",
        "    print_tree(node.false_branch, spacing + \"  \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XlNwj3ZjH7CP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def build_tree(rows,running_node,running_depth,max_depth):\n",
        "#     depth_nodes_total=math.pow(2,running_depth)#number of nodes in that depth\n",
        "#     temp_node=0\n",
        "#     #Should check the running node is in which depth and current node number \n",
        "#     while(running_node>-1):\n",
        "      \n",
        "      \n",
        "#       running_node-=1\n",
        "      \n",
        "    \n",
        "    \n",
        "    \n",
        "#     gain, question = find_best_split(rows)\n",
        "#     if gain == 0:\n",
        "#         return Leaf(rows)\n",
        "# #     true_rows, false_rows = partition(rows, question)\n",
        "   \n",
        "#     if temp_node<running_node:\n",
        "#       #make decision node and true branch and false branch\n",
        "#       true_rows, false_rows = partition(rows, question)\n",
        "#       true_branch = build_tree(true_rows,max_depth)\n",
        "#       false_branch = build_tree(false_rows,max_depth)\n",
        "#       return Decision_Node(question, true_branch, false_branch)\n",
        "\n",
        "#     if temp_node==depth_nodes_total:\n",
        "#         true_rows, false_rows = partition(rows, question)\n",
        "#         true_branch=Leaf(true_rows)\n",
        "#         false_branch=Leaf(false_rows)\n",
        "#         return Decision_Node(question, true_branch, false_branch)      \n",
        "    \n",
        "# #     if(max_depth>-1):\n",
        "# #       max_depth-=1\n",
        "      \n",
        "# #       true_branch = build_tree(true_rows,max_depth)\n",
        "\n",
        "\n",
        "# #       false_branch = build_tree(false_rows,max_depth)\n",
        "\n",
        "\n",
        "# #       return Decision_Node(question, true_branch, false_branch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NMhK1wni-Wvw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def build_tree(rows,num_nodes):\n",
        "#   gain, question = find_best_split(rows)\n",
        "#   if gain == 0:\n",
        "#       return Leaf(rows)\n",
        "#   while(num_nodes>0):\n",
        "#     true_rows, false_rows = partition(rows, question)\n",
        "#     Decision_Node(question, true_branch, false_branch)\n",
        "#     num_nodes-=1\n",
        "#   if num_nodes==1:\n",
        "#       true_rows, false_rows = partition(rows, question)\n",
        "#       true_branch=Leaf(true_rows)\n",
        "#       false_branch=Leaf(false_rows)\n",
        "#   return Decision_Node(question, true_branch, false_branch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vf8-GdKwFOIl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_tree(rows,max_depth,depth):\n",
        "    \"\"\"Builds the tree.\n",
        "\n",
        "    Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
        "    for the base case (no further information gain). 3) Prepare for\n",
        "    giant stack traces.\n",
        "    \"\"\"\n",
        "\n",
        "    # Try partitioing the dataset on each of the unique attribute,\n",
        "    # calculate the information gain,\n",
        "    # and return the question that produces the highest gain.\n",
        "    print(\"Depth: \",depth)\n",
        "    gain, question = find_best_split(rows)\n",
        "  \n",
        "    # Base case: no further info gain\n",
        "    # Since we can ask no further questions,\n",
        "    # we'll return a leaf.\n",
        "    if gain == 0 or depth>=max_depth:\n",
        "        print(\"Created Leaf Node\")\n",
        "        depth=depth-1\n",
        "        return Leaf(rows)\n",
        "    if depth<max_depth:\n",
        "      true_rows, false_rows = partition(rows, question)\n",
        "      print(\"Creating True Branch\")\n",
        "      true_branch = build_tree(true_rows,max_depth,depth+1)\n",
        "\n",
        "      print(\"Creating False Branch\")\n",
        "      false_branch = build_tree(false_rows,max_depth,depth+1)\n",
        "\n",
        "      # Return a Question node.\n",
        "      # This records the best feature / value to ask at this point,\n",
        "      # as well as the branches to follow\n",
        "      # dependingo on the answer.\n",
        "      depth=depth-1\n",
        "      return Decision_Node(question, true_branch, false_branch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z2sahEl6USzM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#working\n",
        "# def build_tree(rows):\n",
        "#     \"\"\"Builds the tree.\n",
        "\n",
        "#     Rules of recursion: 1) Believe that it works. 2) Start by checking\n",
        "#     for the base case (no further information gain). 3) Prepare for\n",
        "#     giant stack traces.\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Try partitioing the dataset on each of the unique attribute,\n",
        "#     # calculate the information gain,\n",
        "#     # and return the question that produces the highest gain.\n",
        "#     gain, question = find_best_split(rows)\n",
        "\n",
        "#     # Base case: no further info gain\n",
        "#     # Since we can ask no further questions,\n",
        "#     # we'll return a leaf.\n",
        "#     if gain == 0:\n",
        "#         print(\"Created Leaf Node\")\n",
        "#         return Leaf(rows)\n",
        "\n",
        "#     # If we reach here, we have found a useful feature / value\n",
        "#     # to partition on.\n",
        "#     true_rows, false_rows = partition(rows, question)\n",
        "\n",
        "#     # Recursively build the true branch.\n",
        "#     print(\"Creating True Branch\")\n",
        "#     true_branch = build_tree(true_rows)\n",
        "\n",
        "#     # Recursively build the false branch.\n",
        "#     print(\"Creating False Branch\")\n",
        "#     false_branch = build_tree(false_rows)\n",
        "\n",
        "#     # Return a Question node.\n",
        "#     # This records the best feature / value to ask at this point,\n",
        "#     # as well as the branches to follow\n",
        "#     # dependingo on the answer.\n",
        "#     return Decision_Node(question, true_branch, false_branch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vU2keUQAIBNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "87552be9-3bcb-4fc2-f3c8-a4d08fe26b0b"
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "max_depth=2\n",
        "num_nodes_total=(math.pow(2,max_depth+1)-1)\n",
        "current_node=0\n",
        "current_depth=0\n",
        "rows=train_set\n",
        "if(current_depth<=max_depth)\n",
        "  while(current_node<=num_nodes_total):\n",
        "    my_tree = build_tree(rows,current_node,current_depth,max_depth)\n",
        "    for row in test_set:\n",
        "      print (\"Actual: %s. Predicted: %s\" %\n",
        "             (row[-1], print_leaf(classify(row, my_tree))))\n",
        "    current_node+=1\n",
        "  current_depth+=1\n",
        "# my_tree=build_tree(train_set,num_nodes)\n",
        "print_tree(my_tree)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-accadb414a01>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    if(current_depth<=max_depth)\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qCFOFO1mPDIX",
        "colab_type": "code",
        "outputId": "e3e2353b-2974-42b8-978d-b052ec632105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "max_depth=1\n",
        "# num_nodes=(math.pow(2,max_depth+1)-1)\n",
        "my_tree=build_tree(train_set,max_depth,0)\n",
        "print_tree(my_tree)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Depth:  0\n",
            "Best Question:  Is Cellsize >= 3.0?\n",
            "Best Gain:  0.34040346770471613\n",
            "Creating True Branch\n",
            "Depth:  1\n",
            "Best Question:  Is Cellshape >= 3.0?\n",
            "Best Gain:  0.0637553286138829\n",
            "Created Leaf Node\n",
            "Creating False Branch\n",
            "Depth:  1\n",
            "Best Question:  Is Nuclei >= 6.0?\n",
            "Best Gain:  0.034568181818181797\n",
            "Created Leaf Node\n",
            "Is Cellsize >= 3.0?\n",
            "--> True:\n",
            "  Predict {4.0: 152, 2.0: 22}\n",
            "--> False:\n",
            "  Predict {2.0: 273, 4.0: 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i0WnIVJkB06a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Question and gain: Is Temperature == hot? 0.03124999999999989\n",
        "Question and gain: Is Temperature == cool? 0.031249999999999917\n",
        "Question and gain: Is Humidity == low? 0.031249999999999917\n",
        "Question and gain: Is Humidity == high? 0.03124999999999989\n",
        "Question and gain: Is Sky_Condition == clear? 0.06124999999999997\n",
        "Question and gain: Is Sky_Condition == cloudy? 0.06124999999999997\n",
        "Best Question:  Is Sky_Condition == cloudy?\n",
        "Best Gain:  0.06124999999999997\n",
        "Creating True Branch\n",
        "Question and gain: Is Temperature == hot? 0.03125\n",
        "Question and gain: Is Temperature == cool? 0.03125\n",
        "Question and gain: Is Humidity == low? 0.06125000000000011\n",
        "Question and gain: Is Humidity == high? 0.06125000000000011\n",
        "Best Question:  Is Humidity == high?\n",
        "Best Gain:  0.06125000000000011\n",
        "Creating True Branch\n",
        "Question and gain: Is Temperature == hot? 0.01999999999999985\n",
        "Question and gain: Is Temperature == cool? 0.01999999999999985\n",
        "Best Question:  Is Temperature == cool?\n",
        "Best Gain:  0.01999999999999985\n",
        "Creating True Branch\n",
        "Best Question:  None\n",
        "Best Gain:  0\n",
        "Created Leaf Node\n",
        "Creating False Branch\n",
        "Best Question:  None\n",
        "Best Gain:  0\n",
        "Created Leaf Node\n",
        "Creating False Branch\n",
        "Question and gain: Is Temperature == hot? 0.0449999999999999\n",
        "Question and gain: Is Temperature == cool? 0.04499999999999993\n",
        "Best Question:  Is Temperature == cool?\n",
        "Best Gain:  0.04499999999999993\n",
        "Creating True Branch\n",
        "Best Question:  None\n",
        "Best Gain:  0\n",
        "Created Leaf Node\n",
        "Creating False Branch\n",
        "Best Question:  None\n",
        "Best Gain:  0\n",
        "Created Leaf Node\n",
        "Creating False Branch\n",
        "Question and gain: Is Temperature == hot? 0.03124999999999989\n",
        "Question and gain: Is Temperature == cool? 0.03124999999999989\n",
        "Question and gain: Is Humidity == low? 0.01125000000000001\n",
        "Question and gain: Is Humidity == high? 0.01125000000000001\n",
        "Best Question:  Is Temperature == cool?\n",
        "Best Gain:  0.03124999999999989\n",
        "Creating True Branch\n",
        "Question and gain: Is Humidity == low? 0.0050000000000002265\n",
        "Question and gain: Is Humidity == high? 0.0050000000000002265\n",
        "Best Question:  Is Humidity == high?\n",
        "Best Gain:  0.0050000000000002265\n",
        "Creating True Branch\n",
        "Best Question:  None\n",
        "Best Gain:  0\n",
        "Created Leaf Node\n",
        "Creating False Branch\n",
        "Best Question:  None\n",
        "Best Gain:  0\n",
        "Created Leaf Node\n",
        "Creating False Branch\n",
        "Question and gain: Is Humidity == low? 0.019999999999999907\n",
        "Question and gain: Is Humidity == high? 0.019999999999999934\n",
        "Best Question:  Is Humidity == high?\n",
        "Best Gain:  0.019999999999999934\n",
        "Creating True Branch\n",
        "Best Question:  None\n",
        "Best Gain:  0\n",
        "Created Leaf Node\n",
        "Creating False Branch\n",
        "Best Question:  None\n",
        "Best Gain:  0\n",
        "Created Leaf Node\n",
        "Is Sky_Condition == cloudy?\n",
        "--> True:\n",
        "  Is Humidity == high?\n",
        "  --> True:\n",
        "    Is Temperature == cool?\n",
        "    --> True:\n",
        "      Predict {1: 7, 0: 3}\n",
        "    --> False:\n",
        "      Predict {1: 9, 0: 1}\n",
        "  --> False:\n",
        "    Is Temperature == cool?\n",
        "    --> True:\n",
        "      Predict {1: 3, 0: 7}\n",
        "    --> False:\n",
        "      Predict {1: 6, 0: 4}\n",
        "--> False:\n",
        "  Is Temperature == cool?\n",
        "  --> True:\n",
        "    Is Humidity == high?\n",
        "    --> True:\n",
        "      Predict {1: 2, 0: 8}\n",
        "    --> False:\n",
        "      Predict {1: 1, 0: 9}\n",
        "  --> False:\n",
        "    Is Humidity == high?\n",
        "    --> True:\n",
        "      Predict {1: 5, 0: 5}\n",
        "    --> False:\n",
        "      Predict {1: 3, 0: 7}"
      ]
    },
    {
      "metadata": {
        "id": "ppdZanNYI-bR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predicting the Class"
      ]
    },
    {
      "metadata": {
        "id": "IZNRIv33I91h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classify(row, node):\n",
        "    \"\"\"See the 'rules of recursion' above.\"\"\"\n",
        "\n",
        "    # Base case: we've reached a leaf\n",
        "    if isinstance(node, Leaf):\n",
        "        return node.predictions\n",
        "\n",
        "    # Decide whether to follow the true-branch or the false-branch.\n",
        "    # Compare the feature / value stored in the node,\n",
        "    # to the example we're considering.\n",
        "    if node.question.match(row):\n",
        "        return classify(row, node.true_branch)\n",
        "    else:\n",
        "        return classify(row, node.false_branch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h28YEgxXJMYx",
        "colab_type": "code",
        "outputId": "1c9d1cd8-6814-4dff-b030-52474346d6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "cell_type": "code",
      "source": [
        "classify(test_set[11], my_tree)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-327ec429e43c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_set' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "_KIZBuPTJQb6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_leaf(counts):\n",
        "    \"\"\"A nicer way to print the predictions at a leaf.\"\"\"\n",
        "    total = sum(counts.values()) * 1.0\n",
        "    probs = {}\n",
        "    for lbl in counts.keys():\n",
        "        probs[lbl] = str(int(counts[lbl] / total * 100)) + \"%\"\n",
        "    return probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1WDeXodcJY84",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#print_leaf(classify(train_set[], my_tree))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9jGDOsPXJepz",
        "colab_type": "code",
        "outputId": "f13ee546-4964-4176-ddad-a45d213928b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3847
        }
      },
      "cell_type": "code",
      "source": [
        "for row in test_set:\n",
        "    print (\"Actual: %s. Predicted: %s\" %\n",
        "           (row[-1], print_leaf(classify(row, my_tree))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 4.0. Predicted: {4.0: '85%', 2.0: '14%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n",
            "Actual: 2.0. Predicted: {2.0: '97%', 4.0: '2%'}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}